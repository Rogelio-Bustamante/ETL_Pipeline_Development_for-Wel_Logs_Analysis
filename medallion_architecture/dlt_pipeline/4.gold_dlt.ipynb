{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56820386-3589-4ed3-9d11-b86acbdaa801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data calculations and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc05bf3-6d0f-4b23-ae57-587715c37664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87f03dd8-849b-4173-94b8-28c5419247aa",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754513569465}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(name = \"gold_unpivoted\")\n",
    "\n",
    "def gold_unpivoted():\n",
    "  df = dlt.read(\"all_wells_gold\")\n",
    "\n",
    "  unpivotExpr = \"stack(16, 'GR', GR, 'ILD', ILD, 'ILM', ILM, 'CALI', CALI, 'DPHI', DPHI, 'DT', DT, 'DT2', DT2, 'NPHI', NPHI, 'RHOB', RHOB, 'SFLU', SFLU, 'SP', SP, 'TEN', TEN, 'POROSITY', POROSITY, 'Perm', PERM, 'Fluvialfacie', Fluvialfacies, 'NetGross', NetGross) as (log_name, values)\"\n",
    "  \n",
    "  return (\n",
    "    df.selectExpr(\"well_id\", \"DEPTH\", unpivotExpr)\n",
    "  )\n",
    "\n",
    "@dlt.table(\n",
    "    name = \"gold_unpivoted_snapshot\",\n",
    "    comment = \"Direct batch snapshot from Gold, without streaming, for windows calculations\",\n",
    "    table_properties = {\"layer\": \"gold\", \"type\": \"well log\"}\n",
    ")\n",
    "def create_gold_unpivoted_snapshot():\n",
    "    return spark.sql(\"\"\"\n",
    "        SELECT well_id, DEPTH, log_name, CAST(values AS DOUBLE) AS values\n",
    "        FROM (\n",
    "            SELECT well_id, DEPTH, log_name, CAST(values AS DOUBLE) AS values\n",
    "            FROM LIVE.gold_unpivoted\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "@dlt.table(\n",
    "    name = \"gold_unpivoted_cleaned\",\n",
    "    comment = \"Cleaned unpivoted table that contains all wells in gold layer without null values\",\n",
    "    table_properties = {\"layer\" : \"gold\", \"type\" : \"well log\"}\n",
    ")\n",
    "\n",
    "def gold_unpivoted_cleaned():\n",
    "  df2 = dlt.read(\"gold_unpivoted_snapshot\")\n",
    "\n",
    "  return (\n",
    "    df2\n",
    "    .select(\"well_id\", \"DEPTH\", \"log_name\", col(\"values\").cast(\"double\").alias(\"values\"))\n",
    "    .where((col(\"values\") != lit(-999.25)) & col(\"values\").isNotNull())\n",
    "    .orderBy(\"well_id\", \"DEPTH\", \"log_name\", ascending=[True, True, True])\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6dfd1d4-a892-47ad-b90b-f088d8e0e17a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Making the coresponding aggregations\n",
    "@dlt.table(\n",
    "    name = \"gold_statistics_summary\",\n",
    "    comment = \"Table that contains logs statistical summary per well in gold layer\",\n",
    "    table_properties = {\"layer\" : \"gold\", \"type\" : \"well log\"}\n",
    ")\n",
    "def gold_statistics_summary():\n",
    "  \n",
    "  # Making the coresponding aggregations \n",
    "  df_agg = (dlt.read(\"gold_unpivoted_snapshot\")\n",
    "           .groupBy(\"well_id\", \"log_name\")\n",
    "           .agg(\n",
    "                min(when((col(\"values\") != \"-999.25\") & col(\"values\").isNotNull(), col(\"values\"))).alias(\"min_value\"),\n",
    "                max(when((col(\"values\") != \"-999.25\") & col(\"values\").isNotNull(), col(\"values\"))).alias(\"max_value\"),\n",
    "                avg(when((col(\"values\") != \"-999.25\") & col(\"values\").isNotNull(), col(\"values\"))).alias(\"avg_value\"),\n",
    "                stddev(when((col(\"values\") != \"-999.25\") & col(\"values\").isNotNull(), col(\"values\"))).alias(\"stddev_value\"),\n",
    "                count(\"values\").alias(\"total_values_count\"),\n",
    "                count(when((col(\"values\") != \"-999.25\") & col(\"values\").isNotNull(), col(\"values\"))).alias(\"valid_values_count\"))\n",
    "           .orderBy(\"well_id\", \"log_name\", ascending=[True, True])\n",
    "           .where((col(\"total_values_count\") != 0) & (col(\"valid_values_count\") != 0))\n",
    "  )\n",
    "  \n",
    "  # Identify the min and max valid depth from each log\n",
    "  window_spec_min = Window.partitionBy(\"well_id\", \"log_name\").orderBy(col(\"DEPTH\").asc())\n",
    "  window_spec_max = Window.partitionBy(\"well_id\", \"log_name\").orderBy(col(\"DEPTH\").desc())\n",
    "  \n",
    "  df_min_depth = (dlt.read(\"gold_unpivoted_cleaned\")\n",
    "                  .withColumn(\"row_num\", row_number().over(window_spec_min))\n",
    "                  .where(col(\"row_num\") == 1)\n",
    "                  .select(\"well_id\", \"log_name\", col(\"DEPTH\").alias(\"min_depth_valid\"))\n",
    "  )\n",
    "  \n",
    "  df_max_depth = (dlt.read(\"gold_unpivoted_cleaned\")\n",
    "                  .withColumn(\"row_num\", row_number().over(window_spec_max))\n",
    "                  .where(col(\"row_num\") == 1)\n",
    "                  .select(\"well_id\", \"log_name\", col(\"DEPTH\").alias(\"max_depth_valid\"))\n",
    "  )\n",
    "  \n",
    "  # Calculating the difference between depths to find the measurement intervals\n",
    "  df_with_diff = (dlt.read(\"gold_unpivoted_cleaned\").withColumn(\n",
    "      \"depth_diff\",\n",
    "      col(\"DEPTH\") - lag(\"DEPTH\", 1).over(window_spec_min)\n",
    "      )\n",
    "  )\n",
    "  \n",
    "  # Calculating the sum between all measurement intervals to find the total valid interval\n",
    "  df_valid_depth = (df_with_diff\n",
    "               .groupBy(\"well_id\", \"log_name\")\n",
    "               .agg(\n",
    "                   sum(\"depth_diff\").alias(\"valid_interval_meters\")\n",
    "               )\n",
    "  )\n",
    "  \n",
    "  # Joining everything to make the final table\n",
    "  return (\n",
    "      df_min_depth\n",
    "      .join(df_max_depth, on=[\"well_id\", \"log_name\"], how=\"inner\")\n",
    "      .join(df_valid_depth, on=[\"well_id\", \"log_name\"], how=\"inner\")    \n",
    "      .join(df_agg, on=[\"well_id\", \"log_name\"], how=\"inner\")\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.gold_dlt",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
