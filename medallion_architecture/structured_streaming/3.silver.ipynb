{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc05bf3-6d0f-4b23-ae57-587715c37664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e985fac-ed26-4295-932a-35db6b2d072c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoints_path = \"/Volumes/well_logs_nrt/autoloader/checkpoints_volume/all_wells_gold_checkpoints\"\n",
    "output_path = \"/Volumes/well_logs_nrt/gold/deltalake_folders_volume/all_wells_gold\"\n",
    "input_path = \"/Volumes/well_logs_nrt/silver/deltalake_folders_volume/all_wells_silver\"\n",
    "\n",
    "df = spark.readStream.format(\"delta\").load(input_path)\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "df_cleaned = (df.filter(col(\"well_id\").isNotNull()) \n",
    "            # .filter(col(\"DEPTH\") >= 0)\n",
    "            # Normaliza sentinel de profundidad por si acaso (puedes quitarlo si ya viene como NULL)\n",
    "            #.withColumn(\"DEPTH\", when(col(\"DEPTH\").cast(\"double\") == lit(-999.25), lit(None))\n",
    "                          #.otherwise(col(\"DEPTH\").cast(\"double\")))\n",
    "            .dropDuplicates([\"well_id\", \"measurement_time\"])\n",
    "            .withColumn(\"gold_ingestion_time\", current_timestamp())\n",
    "            .drop(col(\"silver_ingestion_time\"), col(\"_rescued_data\"))\n",
    ")\n",
    "\n",
    "#Data validations\n",
    "\n",
    "df_validated = df_cleaned.withColumn(\n",
    "    \"quality_check\",\n",
    "    when((col(\"DEPTH\") >= 0), \"valid\")\n",
    "    .otherwise(\"Not passed\")\n",
    ")\n",
    "\n",
    "df_validated.writeStream.format(\"delta\") \\\n",
    "  .partitionBy(\"well_id\") \\\n",
    "  .option(\"checkpointLocation\", checkpoints_path) \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .trigger(once=True) \\\n",
    "  .start(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdfbbfcd-20d0-482b-97c4-511bfe750db9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.read.format(\"delta\").load(\"/Volumes/well_logs_nrt/gold/deltalake_folders_volume/all_wells_gold\")\n",
    "        .where(\"well_id = 'F02-01_logs'\")\n",
    "        #.orderBy(col(\"well_id\").asc(), col(\"depth\").asc())\n",
    "        .orderBy(\"well_id\", \"DEPTH\", ascending = [True, True])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
